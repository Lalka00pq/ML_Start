{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.56 ðŸš€ Python-3.12.1 torch-2.5.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train3\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "Plotting labels to c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train3\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348      0.502      0.252      0.192     0.0926\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348      0.223      0.742      0.408      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348      0.333      0.734      0.559      0.285\n",
      "\n",
      "3 epochs completed in 0.044 hours.\n",
      "Optimizer stripped from c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train3\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train3\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train3\\weights\\best.pt...\n",
      "Ultralytics 8.3.56 ðŸš€ Python-3.12.1 torch-2.5.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "Model summary (fused): 168 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                   all         20        348       0.33      0.734      0.557      0.285\n",
      "                object         10         63      0.501      0.524      0.522       0.22\n",
      "                object         10        285      0.159      0.944      0.593       0.35\n",
      "Speed: 1.5ms preprocess, 171.6ms inference, 0.0ms loss, 74.8ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train3\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\train.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\train.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "        1/3         0G      2.315      4.011      1.419        392        640:   0%|          | 0/5 [00:09<?, ?it/s]\n",
      "        1/3         0G      2.315      4.011      1.419        392        640:  20%|â–ˆâ–ˆ        | 1/5 [00:09<00:37,  9.35s/it]\n",
      "        1/3         0G      2.299      4.083      1.446        266        640:  20%|â–ˆâ–ˆ        | 1/5 [00:18<00:37,  9.35s/it]\n",
      "        1/3         0G      2.299      4.083      1.446        266        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:18<00:27,  9.27s/it]\n",
      "        1/3         0G      2.285      3.985       1.45        284        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:27<00:27,  9.27s/it]\n",
      "        1/3         0G      2.285      3.985       1.45        284        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:27<00:18,  9.29s/it]\n",
      "        1/3         0G      2.373      3.923      1.452        428        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:37<00:18,  9.29s/it]\n",
      "        1/3         0G      2.373      3.923      1.452        428        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:37<00:09,  9.41s/it]\n",
      "        1/3         0G      2.415      3.793      1.458        467        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:47<00:09,  9.41s/it]\n",
      "        1/3         0G      2.415      3.793      1.458        467        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:47<00:00,  9.46s/it]\n",
      "        1/3         0G      2.415      3.793      1.458        467        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:47<00:00,  9.40s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.61s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "        2/3         0G      2.182      2.369      1.285        385        640:   0%|          | 0/5 [00:09<?, ?it/s]\n",
      "        2/3         0G      2.182      2.369      1.285        385        640:  20%|â–ˆâ–ˆ        | 1/5 [00:09<00:36,  9.13s/it]\n",
      "        2/3         0G      2.025      2.232      1.264        237        640:  20%|â–ˆâ–ˆ        | 1/5 [00:17<00:36,  9.13s/it]\n",
      "        2/3         0G      2.025      2.232      1.264        237        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:17<00:26,  8.87s/it]\n",
      "        2/3         0G       2.09      2.288      1.262        320        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:26<00:26,  8.87s/it]\n",
      "        2/3         0G       2.09      2.288      1.262        320        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:26<00:17,  8.87s/it]\n",
      "        2/3         0G      2.041      2.199      1.241        319        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:35<00:17,  8.87s/it]\n",
      "        2/3         0G      2.041      2.199      1.241        319        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:35<00:08,  8.87s/it]\n",
      "        2/3         0G      1.962      2.074       1.22        232        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:44<00:08,  8.87s/it]\n",
      "        2/3         0G      1.962      2.074       1.22        232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:44<00:00,  8.88s/it]\n",
      "        2/3         0G      1.962      2.074       1.22        232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:44<00:00,  8.89s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.09s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "        3/3         0G      1.679      1.598      1.073        415        640:   0%|          | 0/5 [00:08<?, ?it/s]\n",
      "        3/3         0G      1.679      1.598      1.073        415        640:  20%|â–ˆâ–ˆ        | 1/5 [00:08<00:35,  8.81s/it]\n",
      "        3/3         0G      1.672       1.53      1.103        349        640:  20%|â–ˆâ–ˆ        | 1/5 [00:17<00:35,  8.81s/it]\n",
      "        3/3         0G      1.672       1.53      1.103        349        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:17<00:26,  8.93s/it]\n",
      "        3/3         0G       1.69      1.523      1.097        389        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:27<00:26,  8.93s/it]\n",
      "        3/3         0G       1.69      1.523      1.097        389        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:27<00:18,  9.14s/it]\n",
      "        3/3         0G      1.712      1.548      1.098        185        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:36<00:18,  9.14s/it]\n",
      "        3/3         0G      1.712      1.548      1.098        185        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:36<00:09,  9.25s/it]\n",
      "        3/3         0G      1.723      1.487      1.089        541        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:46<00:09,  9.25s/it]\n",
      "        3/3         0G      1.723      1.487      1.089        541        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:46<00:00,  9.49s/it]\n",
      "        3/3         0G      1.723      1.487      1.089        541        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:46<00:00,  9.31s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.27s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.71s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo train model=yolov8s.pt data=data.yaml epochs=3 batch=16 workers=4 imgsz=640 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\n",
    "    r'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train3\\weights\\best_yolo8.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-\\images.jpg: 480x640 51 objects, 173.6ms\n",
      "Speed: 7.0ms preprocess, 173.6ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'object', 1: 'object'}\n",
       " obb: None\n",
       " orig_img: array([[[ 96,  91,  90],\n",
       "         [ 98,  93,  92],\n",
       "         [101,  96,  95],\n",
       "         ...,\n",
       "         [204, 214, 214],\n",
       "         [188, 198, 198],\n",
       "         [192, 202, 202]],\n",
       " \n",
       "        [[ 88,  83,  82],\n",
       "         [ 92,  87,  86],\n",
       "         [ 98,  93,  92],\n",
       "         ...,\n",
       "         [187, 197, 197],\n",
       "         [198, 208, 208],\n",
       "         [192, 202, 202]],\n",
       " \n",
       "        [[ 81,  76,  75],\n",
       "         [ 85,  80,  79],\n",
       "         [ 90,  86,  85],\n",
       "         ...,\n",
       "         [187, 197, 197],\n",
       "         [196, 206, 206],\n",
       "         [192, 202, 202]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 87, 103, 119],\n",
       "         [ 85, 101, 117],\n",
       "         [ 83,  99, 112],\n",
       "         ...,\n",
       "         [109, 115, 126],\n",
       "         [ 89,  96, 105],\n",
       "         [ 83,  90,  99]],\n",
       " \n",
       "        [[ 85, 102, 115],\n",
       "         [ 83, 100, 113],\n",
       "         [ 80,  96, 109],\n",
       "         ...,\n",
       "         [102, 109, 118],\n",
       "         [ 82,  89,  98],\n",
       "         [ 99, 106, 115]],\n",
       " \n",
       "        [[ 84, 101, 114],\n",
       "         [ 82,  99, 112],\n",
       "         [ 80,  96, 109],\n",
       "         ...,\n",
       "         [ 88,  95, 104],\n",
       "         [ 68,  75,  84],\n",
       "         [111, 119, 126]]], shape=(190, 265, 3), dtype=uint8)\n",
       " orig_shape: (190, 265)\n",
       " path: 'C:\\\\Users\\\\User\\\\Desktop\\\\ML_projects\\\\ML_Start_Caisar\\\\ML_Start\\\\src\\\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\\\images.jpg'\n",
       " probs: None\n",
       " save_dir: 'c:\\\\Users\\\\User\\\\Desktop\\\\ML_projects\\\\ML_Start_Caisar\\\\ML_Start\\\\runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 7.000207901000977, 'inference': 173.63643646240234, 'postprocess': 14.003276824951172}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "    r'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\images.jpg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.56  Python-3.12.1 torch-2.5.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        348       0.33      0.734      0.557      0.285\n",
      "                object         10         63      0.501      0.524      0.522       0.22\n",
      "                object         10        285      0.159      0.944      0.593       0.35\n",
      "Speed: 1.6ms preprocess, 139.1ms inference, 0.0ms loss, 66.3ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\val\u001b[0m\n",
      "0.2848870119308476\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()\n",
    "print(metrics.box.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-\\images.jpg: 480x640 51 objects, 126.7ms\n",
      "Speed: 2.2ms preprocess, 126.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(r'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\images.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[174.4877,  54.2678, 189.7748,  71.8918]])\n",
      "tensor([[180.0333,  74.8031, 198.6808,  95.7376]])\n",
      "tensor([[ 85.3385, 109.7029, 103.2126, 125.8515]])\n",
      "tensor([[129.9175, 101.4352, 142.3044, 115.2384]])\n",
      "tensor([[ 0.7478, 25.2588, 15.8700, 40.8576]])\n",
      "tensor([[20.3694, 39.1968, 31.7277, 48.8167]])\n",
      "tensor([[239.3906,  72.0653, 247.4647,  86.1369]])\n",
      "tensor([[175.9850,  61.3002, 186.4948,  72.4661]])\n",
      "tensor([[167.6488, 167.7839, 179.4447, 183.6036]])\n",
      "tensor([[169.4404, 171.5388, 179.0078, 183.9975]])\n",
      "tensor([[175.1624, 133.0665, 188.4036, 149.2074]])\n",
      "tensor([[31.1488, 50.5072, 42.5408, 63.5983]])\n",
      "tensor([[175.5368,  57.9931, 189.3186,  72.7855]])\n",
      "tensor([[217.2863, 176.3662, 229.2071, 189.5818]])\n",
      "tensor([[219.3190, 176.4331, 228.8259, 184.6781]])\n",
      "tensor([[139.8339, 175.4453, 151.6484, 187.1184]])\n",
      "tensor([[178.9095,  81.5366, 189.3147,  90.1668]])\n",
      "tensor([[219.6994, 158.7457, 229.4869, 168.3949]])\n",
      "tensor([[211.1633, 158.8748, 218.7762, 168.0287]])\n",
      "tensor([[105.0369, 181.4638, 114.8196, 189.4301]])\n",
      "tensor([[158.2361,  46.6803, 167.8985,  56.2360]])\n",
      "tensor([[163.8035, 168.5372, 178.9480, 183.9371]])\n",
      "tensor([[130.5156, 102.9835, 142.2654, 118.9340]])\n",
      "tensor([[178.7729,  31.6985, 186.6229,  41.4127]])\n",
      "tensor([[139.5977, 174.9365, 147.3606, 187.0777]])\n",
      "tensor([[239.6500,  71.4707, 247.1648,  81.7643]])\n",
      "tensor([[148.2513, 159.7248, 158.3129, 169.6473]])\n",
      "tensor([[178.9397,  81.9024, 190.8539,  93.9822]])\n",
      "tensor([[175.4145, 132.3104, 186.5761, 142.3983]])\n",
      "tensor([[144.4970, 175.1419, 151.6420, 184.3411]])\n",
      "tensor([[186.5898,  75.7652, 199.0151,  95.2874]])\n",
      "tensor([[105.1992, 176.7895, 115.3006, 189.3766]])\n",
      "tensor([[177.7532,  53.3147, 189.7641,  66.4783]])\n",
      "tensor([[115.8037,   7.8140, 129.0789,  24.2707]])\n",
      "tensor([[228.3474, 142.8217, 234.9536, 152.5746]])\n",
      "tensor([[202.5668, 173.3488, 209.3200, 182.3367]])\n",
      "tensor([[202.1538, 173.6301, 209.9042, 184.2620]])\n",
      "tensor([[196.3803,  35.2434, 202.1942,  43.7132]])\n",
      "tensor([[204.5096, 169.1896, 216.3678, 188.9274]])\n",
      "tensor([[185.9422,  82.3066, 197.2690,  95.7380]])\n",
      "tensor([[163.5683, 169.9713, 175.1666, 182.2718]])\n",
      "tensor([[255.4615,  38.4841, 261.2438,  48.0281]])\n",
      "tensor([[224.5350,  36.0123, 235.7184,  47.6540]])\n",
      "tensor([[144.6835, 174.8704, 152.7310, 186.4926]])\n",
      "tensor([[160.3366,  17.3230, 167.8819,  23.3893]])\n",
      "tensor([[204.9021,  39.5563, 209.6528,  49.6135]])\n",
      "tensor([[178.9498,  79.9754, 188.6506,  88.6343]])\n",
      "tensor([[168.6872, 166.8175, 179.8398, 178.3931]])\n",
      "tensor([[144.8404, 171.9671, 151.4509, 182.5835]])\n",
      "tensor([[175.3737, 132.1335, 187.8585, 145.3963]])\n",
      "tensor([[139.9083, 179.1373, 147.0248, 187.1551]])\n"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "    for box in boxes:\n",
    "        print(box.xyxy)\n",
    "img = results[0].plot()\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('Result', img_rgb)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ YOLO10n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.56 ðŸš€ Python-3.12.1 torch-2.5.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov10n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train5\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    862108  ultralytics.nn.modules.head.v10Detect        [2, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2,707,820 parameters, 2,707,804 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "Plotting labels to c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train5\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348     0.0144     0.0238     0.0193     0.0122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348     0.0739     0.0634     0.0512     0.0347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348     0.0316      0.153     0.0484     0.0297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348     0.0335      0.175     0.0574      0.034\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348     0.0248      0.226     0.0883     0.0407\n",
      "\n",
      "5 epochs completed in 0.046 hours.\n",
      "Optimizer stripped from c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train5\\weights\\last.pt, 5.7MB\n",
      "Optimizer stripped from c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train5\\weights\\best.pt, 5.7MB\n",
      "\n",
      "Validating c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train5\\weights\\best.pt...\n",
      "Ultralytics 8.3.56 ðŸš€ Python-3.12.1 torch-2.5.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "YOLOv10n summary (fused): 285 layers, 2,695,196 parameters, 0 gradients, 8.2 GFLOPs\n",
      "                   all         20        348     0.0267      0.234     0.0898     0.0416\n",
      "                object         10         63      0.038      0.159     0.0894     0.0543\n",
      "                object         10        285     0.0153      0.309     0.0902     0.0289\n",
      "Speed: 1.3ms preprocess, 74.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train5\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\train.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\train.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "        1/5         0G      5.018      8.369      2.849        392        640:   0%|          | 0/5 [00:06<?, ?it/s]\n",
      "        1/5         0G      5.018      8.369      2.849        392        640:  20%|â–ˆâ–ˆ        | 1/5 [00:06<00:27,  6.87s/it]\n",
      "        1/5         0G      4.863      8.528      2.798        266        640:  20%|â–ˆâ–ˆ        | 1/5 [00:14<00:27,  6.87s/it]\n",
      "        1/5         0G      4.863      8.528      2.798        266        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:14<00:21,  7.26s/it]\n",
      "        1/5         0G      4.783      8.502      2.817        284        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:22<00:21,  7.26s/it]\n",
      "        1/5         0G      4.783      8.502      2.817        284        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:22<00:15,  7.74s/it]\n",
      "        1/5         0G      4.962      8.483      2.809        428        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:30<00:15,  7.74s/it]\n",
      "        1/5         0G      4.962      8.483      2.809        428        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:30<00:07,  7.68s/it]\n",
      "        1/5         0G      5.039      8.443      2.787        467        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:36<00:07,  7.68s/it]\n",
      "        1/5         0G      5.039      8.443      2.787        467        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:36<00:00,  7.29s/it]\n",
      "        1/5         0G      5.039      8.443      2.787        467        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:36<00:00,  7.38s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.89s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "        2/5         0G      4.614      8.277      2.454        385        640:   0%|          | 0/5 [00:05<?, ?it/s]\n",
      "        2/5         0G      4.614      8.277      2.454        385        640:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:21,  5.35s/it]\n",
      "        2/5         0G      4.326      8.222      2.357        237        640:  20%|â–ˆâ–ˆ        | 1/5 [00:10<00:21,  5.35s/it]\n",
      "        2/5         0G      4.326      8.222      2.357        237        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10<00:15,  5.20s/it]\n",
      "        2/5         0G      4.445      8.181      2.357        320        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:15<00:15,  5.20s/it]\n",
      "        2/5         0G      4.445      8.181      2.357        320        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:15<00:10,  5.31s/it]\n",
      "        2/5         0G      4.308      8.081       2.31        319        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:21<00:10,  5.31s/it]\n",
      "        2/5         0G      4.308      8.081       2.31        319        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:21<00:05,  5.27s/it]\n",
      "        2/5         0G      4.124       8.01      2.259        232        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:05,  5.27s/it]\n",
      "        2/5         0G      4.124       8.01      2.259        232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  5.26s/it]\n",
      "        2/5         0G      4.124       8.01      2.259        232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  5.27s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "        3/5         0G      3.718      7.665      2.033        415        640:   0%|          | 0/5 [00:04<?, ?it/s]\n",
      "        3/5         0G      3.718      7.665      2.033        415        640:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:19,  4.88s/it]\n",
      "        3/5         0G      3.544      7.488      2.018        349        640:  20%|â–ˆâ–ˆ        | 1/5 [00:10<00:19,  4.88s/it]\n",
      "        3/5         0G      3.544      7.488      2.018        349        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10<00:15,  5.03s/it]\n",
      "        3/5         0G      3.595       7.43      2.026        389        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:15<00:15,  5.03s/it]\n",
      "        3/5         0G      3.595       7.43      2.026        389        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:15<00:10,  5.24s/it]\n",
      "        3/5         0G      3.678       7.39      2.053        185        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:20<00:10,  5.24s/it]\n",
      "        3/5         0G      3.678       7.39      2.053        185        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:20<00:05,  5.14s/it]\n",
      "        3/5         0G      3.669      7.318       2.03        541        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:05,  5.14s/it]\n",
      "        3/5         0G      3.669      7.318       2.03        541        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  5.37s/it]\n",
      "        3/5         0G      3.669      7.318       2.03        541        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  5.26s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "        4/5         0G      3.683      6.776      1.937        401        640:   0%|          | 0/5 [00:05<?, ?it/s]\n",
      "        4/5         0G      3.683      6.776      1.937        401        640:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:23,  5.76s/it]\n",
      "        4/5         0G      3.371      6.632      1.905        344        640:  20%|â–ˆâ–ˆ        | 1/5 [00:11<00:23,  5.76s/it]\n",
      "        4/5         0G      3.371      6.632      1.905        344        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:11<00:16,  5.46s/it]\n",
      "        4/5         0G      3.498      6.652      1.911        440        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:16<00:16,  5.46s/it]\n",
      "        4/5         0G      3.498      6.652      1.911        440        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:16<00:10,  5.44s/it]\n",
      "        4/5         0G      3.483      6.606      1.921        289        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:21<00:10,  5.44s/it]\n",
      "        4/5         0G      3.483      6.606      1.921        289        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:21<00:05,  5.33s/it]\n",
      "        4/5         0G      3.403      6.596      1.909        208        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:26<00:05,  5.33s/it]\n",
      "        4/5         0G      3.403      6.596      1.909        208        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  5.27s/it]\n",
      "        4/5         0G      3.403      6.596      1.909        208        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  5.35s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.55s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "        5/5         0G      3.235      6.351      1.906        343        640:   0%|          | 0/5 [00:05<?, ?it/s]\n",
      "        5/5         0G      3.235      6.351      1.906        343        640:  20%|â–ˆâ–ˆ        | 1/5 [00:05<00:22,  5.68s/it]\n",
      "        5/5         0G       3.42       6.38      1.919        353        640:  20%|â–ˆâ–ˆ        | 1/5 [00:10<00:22,  5.68s/it]\n",
      "        5/5         0G       3.42       6.38      1.919        353        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:10<00:16,  5.44s/it]\n",
      "        5/5         0G      3.356      6.404      1.911        349        640:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:17<00:16,  5.44s/it]\n",
      "        5/5         0G      3.356      6.404      1.911        349        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:17<00:11,  5.74s/it]\n",
      "        5/5         0G      3.396       6.41        1.9        393        640:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:23<00:11,  5.74s/it]\n",
      "        5/5         0G      3.396       6.41        1.9        393        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:23<00:05,  5.85s/it]\n",
      "        5/5         0G      3.429      6.419      1.896        478        640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:29<00:05,  5.85s/it]\n",
      "        5/5         0G      3.429      6.419      1.896        478        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  6.00s/it]\n",
      "        5/5         0G      3.429      6.419      1.896        478        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:29<00:00,  5.87s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.82s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.25s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo train model='yolov10n.pt' data='data.yaml' epochs=5 batch=16 workers=4 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolo10 = YOLO(\n",
    "    r'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train5\\weights\\best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-\\combine\\test\\2314c1b5-ec8f-4212-b42f-43365a13fd20.jpg: 640x640 (no detections), 79.8ms\n",
      "Speed: 5.0ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results_10 = model_yolo10(\n",
    "    r'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test\\2314c1b5-ec8f-4212-b42f-43365a13fd20.jpg')\n",
    "for r in results_10:\n",
    "    boxes = r.boxes\n",
    "    for box in boxes:\n",
    "        print(box.xyxy)\n",
    "img_10 = results[0].plot()\n",
    "img_rgb_10 = cv2.cvtColor(img_10, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('Result', img_rgb_10)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.56  Python-3.12.1 torch-2.5.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        348     0.0267      0.234     0.0898     0.0416\n",
      "                object         10         63      0.038      0.159     0.0894     0.0543\n",
      "                object         10        285     0.0153      0.309     0.0902     0.0289\n",
      "Speed: 1.5ms preprocess, 73.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\val2\u001b[0m\n",
      "0.041613469567503836\n"
     ]
    }
   ],
   "source": [
    "metrics_10 = model_yolo10.val()\n",
    "print(metrics_10.box.map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ YOLO11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.56 ðŸš€ Python-3.12.1 torch-2.5.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train6\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "Plotting labels to c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train6\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348     0.0027     0.0899     0.0256    0.00813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348     0.0048      0.125     0.0653     0.0288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348    0.00879      0.183     0.0566     0.0269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348     0.0139      0.241     0.0707     0.0357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "                   all         20        348     0.0143       0.25      0.083     0.0422\n",
      "\n",
      "5 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train6\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train6\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating c:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train6\\weights\\best.pt...\n",
      "Ultralytics 8.3.56 ðŸš€ Python-3.12.1 torch-2.5.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "                   all         20        348     0.0144      0.251      0.083     0.0422\n",
      "                object         10         63    0.00542      0.222       0.12     0.0703\n",
      "                object         10        285     0.0234      0.281     0.0455     0.0142\n",
      "Speed: 5.5ms preprocess, 83.2ms inference, 0.0ms loss, 51.6ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train6\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\train.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\train.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        1/5         0G      2.249       3.73      1.384        658        640:   0%|          | 0/3 [00:09<?, ?it/s]\n",
      "        1/5         0G      2.249       3.73      1.384        658        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:19,  9.62s/it]\n",
      "        1/5         0G      2.424      3.783      1.459        712        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:19<00:19,  9.62s/it]\n",
      "        1/5         0G      2.424      3.783      1.459        712        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:19<00:09,  9.65s/it]\n",
      "        1/5         0G      2.597      3.808      1.504        467        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:24<00:09,  9.65s/it]\n",
      "        1/5         0G      2.597      3.808      1.504        467        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:24<00:00,  7.49s/it]\n",
      "        1/5         0G      2.597      3.808      1.504        467        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:24<00:00,  8.07s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        2/5         0G      2.336      3.796      1.415        622        640:   0%|          | 0/3 [00:08<?, ?it/s]\n",
      "        2/5         0G      2.336      3.796      1.415        622        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:08<00:17,  8.88s/it]\n",
      "        2/5         0G      2.396      3.785      1.401        639        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:17<00:17,  8.88s/it]\n",
      "        2/5         0G      2.396      3.785      1.401        639        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:17<00:08,  8.98s/it]\n",
      "        2/5         0G      2.275      3.738      1.353        232        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:21<00:08,  8.98s/it]\n",
      "        2/5         0G      2.275      3.738      1.353        232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  6.71s/it]\n",
      "        2/5         0G      2.275      3.738      1.353        232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.31s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.35s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        3/5         0G      2.289      3.727      1.335        764        640:   0%|          | 0/3 [00:08<?, ?it/s]\n",
      "        3/5         0G      2.289      3.727      1.335        764        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:08<00:16,  8.44s/it]\n",
      "        3/5         0G      2.162      3.654      1.246        574        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:17<00:16,  8.44s/it]\n",
      "        3/5         0G      2.162      3.654      1.246        574        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:17<00:08,  8.69s/it]\n",
      "        3/5         0G      2.184      3.631      1.228        541        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:21<00:08,  8.69s/it]\n",
      "        3/5         0G      2.184      3.631      1.228        541        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  6.76s/it]\n",
      "        3/5         0G      2.184      3.631      1.228        541        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.26s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.84s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        4/5         0G      1.831      3.381      1.102        745        640:   0%|          | 0/3 [00:09<?, ?it/s]\n",
      "        4/5         0G      1.831      3.381      1.102        745        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:18,  9.24s/it]\n",
      "        4/5         0G      1.906        3.4      1.113        729        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:18<00:18,  9.24s/it]\n",
      "        4/5         0G      1.906        3.4      1.113        729        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:18<00:09,  9.10s/it]\n",
      "        4/5         0G      1.879       3.38      1.109        208        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:22<00:09,  9.10s/it]\n",
      "        4/5         0G      1.879       3.38      1.109        208        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  6.78s/it]\n",
      "        4/5         0G      1.879       3.38      1.109        208        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.42s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.70s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "        5/5         0G      1.876      3.252      1.123        696        640:   0%|          | 0/3 [00:09<?, ?it/s]\n",
      "        5/5         0G      1.876      3.252      1.123        696        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:18,  9.17s/it]\n",
      "        5/5         0G      1.891      3.284      1.105        742        640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:18<00:18,  9.17s/it]\n",
      "        5/5         0G      1.891      3.284      1.105        742        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:18<00:09,  9.22s/it]\n",
      "        5/5         0G       1.91      3.306      1.096        478        640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:22<00:09,  9.22s/it]\n",
      "        5/5         0G       1.91      3.306      1.096        478        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.00s/it]\n",
      "        5/5         0G       1.91      3.306      1.096        478        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.59s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.67s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.58s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo train model='yolo11n.pt' data='data.yaml' epochs=5 batch=32 workers=4 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolo_11 = YOLO(\n",
    "    r'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\train6\\weights\\best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.56  Python-3.12.1 torch-2.5.1+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\combine\\test.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        348     0.0144      0.251      0.083     0.0422\n",
      "                object         10         63    0.00542      0.222       0.12     0.0703\n",
      "                object         10        285     0.0234      0.281     0.0455     0.0142\n",
      "Speed: 2.8ms preprocess, 59.5ms inference, 0.0ms loss, 39.3ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\runs\\detect\\val3\u001b[0m\n",
      "0.042224050273292964\n"
     ]
    }
   ],
   "source": [
    "metrics_11 = model_yolo_11.val()\n",
    "print(metrics_11.box.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-\\images.jpg: 480x640 (no detections), 72.4ms\n",
      "Speed: 1.5ms preprocess, 72.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "results_11 = model_yolo_11(r'C:\\Users\\User\\Desktop\\ML_projects\\ML_Start_Caisar\\ML_Start\\src\\6-Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ\\images.jpg')\n",
    "for r in results_11:\n",
    "    boxes = r.boxes\n",
    "    for box in boxes:\n",
    "        print(box.xyxy)\n",
    "img_11 = results[0].plot()\n",
    "img_rgb_11 = cv2.cvtColor(img_11, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('Result', img_rgb_11)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
